{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02dc8ae-ec68-4ffc-bd24-f54edba98fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Aug 21 12:53:16 2021\n",
    "\n",
    "@author: Administrator\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd232a-3b2b-4583-be93-b2fb79cafb5f",
   "metadata": {},
   "source": [
    "# 1번 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395a1473-a079-449c-9b09-a5ce74fc8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 01 유형(DataSet_01.csv 이용)\n",
    "#\n",
    "# 구분자 : comma(“,”), 4,572 Rows, 5 Columns, UTF-8 인코딩\n",
    "# \n",
    "# 글로벌 전자제품 제조회사에서 효과적인 마케팅 방법을 찾기\n",
    "# 위해서 채널별 마케팅 예산과 매출금액과의 관계를 분석하고자\n",
    "# 한다.\n",
    "# 컬 럼 / 정 의  /   Type\n",
    "# TV   /     TV 마케팅 예산 (억원)  /   Double\n",
    "# Radio / 라디오 마케팅 예산 (억원)  /   Double\n",
    "# Social_Media / 소셜미디어 마케팅 예산 (억원)  / Double\n",
    "# Influencer / 인플루언서 마케팅\n",
    "# (인플루언서의 영향력 크기에 따라 Mega / Macro / Micro / \n",
    "# Nano) / String\n",
    "\n",
    "# SALES / 매출액 / Double\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "# pandas,scipy,numpy,sklearn,statsmodels\n",
    "dat=pd.read_csv('Dataset_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5251770-2c50-42f9-b7a2-3e1624f24fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 1. 데이터 세트 내에 총 결측값의 개수는 몇 개인가? (답안 예시) 23\n",
    "# =============================================================================\n",
    "\n",
    "# 정답\n",
    "dat.isna().sum().sum() # 열별 결측치 수 확인\n",
    "# 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb634405-a7e8-4c6f-9a4e-5fef0c648bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "4567    0\n",
       "4568    0\n",
       "4569    0\n",
       "4570    0\n",
       "4571    0\n",
       "Length: 4572, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 먾아 나오는 문제들\n",
    "# 결측치가 있는 행의 수를 찾아라.\n",
    "dat.isna().sum(axis=1) # 행별 결측치 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8403981a-0682-407e-a34b-b8d41615fb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isna().any(axis=1).sum()\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3368b4ba-6f0d-4a9a-950d-b5c5dd7eb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. TV, Radio, Social Media 등 세 가지 다른 마케팅 채널의 예산과 매출액과의 상관분석을\n",
    "# 통하여 각 채널이 매출에 어느 정도 연관이 있는지 알아보고자 한다. \n",
    "# - 매출액과 가장 강한 상관관계를 가지고 있는 채널의 상관계수를 소수점 5번째\n",
    "# 자리에서 반올림하여 소수점 넷째 자리까지 기술하시오. (답안 예시) 0.1234\n",
    "# =============================================================================\n",
    "\n",
    "# 데이터 종류 수치형\n",
    "dat.columns\n",
    "dat[['TV','Radio','Social_Media','Sales']].corr() # 기본 디폴트 값은 pearson\n",
    "Q2=dat[['TV','Radio','Social_Media','Sales']].corr()\n",
    "Q2_abs=Q2.abs() # 음수 고려할 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd12360-327b-493a-8f56-af085eee3a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999497444941335"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답\n",
    "Q2_abs['Sales'].sort_values(ascending=False)[1]\n",
    "# 0.9994974449941335 -> 0.9995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fdb9d33-a0d5-4fdc-b47e-1552ee8783e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999497444941335"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비교\n",
    "Q2_abs['Sales'].nlargest(2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4f6191a-8c86-4af3-90b1-f4a8cf8dbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 3. 매출액을 종속변수, TV, Radio, Social Media의 예산을 독립변수로 하여 회귀분석을\n",
    "# 수행하였을 때, 세 개의 독립변수의 회귀계수를 큰 것에서부터 작은 것 순으로\n",
    "# 기술하시오. \n",
    "# - 분석 시 결측치가 포함된 행은 제거한 후 진행하며, 회귀계수는 소수점 넷째 자리\n",
    "# 이하는 버리고 소수점 셋째 자리까지 기술하시오. (답안 예시) 0.123\n",
    "# =============================================================================\n",
    "\n",
    "# 독립변수(X),종속변수(Y)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.api import OLS,add_constant # 절현을 위한 상수항 추가\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e7a119-4331-48f1-9d7c-e2efaaa533a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.56256963, -0.00397039,  0.00496402])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat1=dat.dropna()\n",
    "\n",
    "lm=LinearRegression(fit_intercept=True)\n",
    "lm.fit(dat1.drop(columns=['Influencer','Sales']),dat1.Sales)\n",
    "\n",
    "dir(lm)\n",
    "lm.coef_\n",
    "# array([3.56256963,-0.00397039,0.00496402])\n",
    "\n",
    "# 정답\n",
    "# 3.562, 0.004, -0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5aa229a-19fb-4089-9361-124363659daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared (uncentered):</th>      <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>7.951e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 23 Aug 2021</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:59:03</td>     <th>  Log-Likelihood:    </th>          <td> -11367.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4546</td>      <th>  AIC:               </th>          <td>2.274e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4543</td>      <th>  BIC:               </th>          <td>2.276e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>           <td>    3.5609</td> <td>    0.003</td> <td> 1133.941</td> <td> 0.000</td> <td>    3.555</td> <td>    3.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>        <td>   -0.0039</td> <td>    0.010</td> <td>   -0.400</td> <td> 0.689</td> <td>   -0.023</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_Media</th> <td>   -0.0013</td> <td>    0.024</td> <td>   -0.054</td> <td> 0.957</td> <td>   -0.049</td> <td>    0.047</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.061</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.970</td> <th>  Jarque-Bera (JB):  </th> <td>   0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.001</td> <th>  Prob(JB):          </th> <td>   0.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.014</td> <th>  Cond. No.          </th> <td>    35.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                  Sales   R-squared (uncentered):                   1.000\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              1.000\n",
       "Method:                 Least Squares   F-statistic:                          7.951e+06\n",
       "Date:                Mon, 23 Aug 2021   Prob (F-statistic):                        0.00\n",
       "Time:                        10:59:03   Log-Likelihood:                         -11367.\n",
       "No. Observations:                4546   AIC:                                  2.274e+04\n",
       "Df Residuals:                    4543   BIC:                                  2.276e+04\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "TV               3.5609      0.003   1133.941      0.000       3.555       3.567\n",
       "Radio           -0.0039      0.010     -0.400      0.689      -0.023       0.015\n",
       "Social_Media    -0.0013      0.024     -0.054      0.957      -0.049       0.047\n",
       "==============================================================================\n",
       "Omnibus:                        0.061   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.970   Jarque-Bera (JB):                0.038\n",
       "Skew:                          -0.001   Prob(JB):                        0.981\n",
       "Kurtosis:                       3.014   Cond. No.                         35.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dat1.drop(columns=['Influencer','Sales'])\n",
    "xx=add_constant(x)\n",
    "y=dat1.Sales\n",
    "\n",
    "ols1=OLS(y,x).fit() # 상수항 미포함\n",
    "ols1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dde63766-3128-4186-ab7a-46ae3e41537c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.505e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 23 Aug 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:32:17</td>     <th>  Log-Likelihood:    </th> <td> -11366.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4546</td>      <th>  AIC:               </th> <td>2.274e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4542</td>      <th>  BIC:               </th> <td>2.277e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   -0.1340</td> <td>    0.103</td> <td>   -1.303</td> <td> 0.193</td> <td>   -0.336</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>           <td>    3.5626</td> <td>    0.003</td> <td> 1051.118</td> <td> 0.000</td> <td>    3.556</td> <td>    3.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>        <td>   -0.0040</td> <td>    0.010</td> <td>   -0.406</td> <td> 0.685</td> <td>   -0.023</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_Media</th> <td>    0.0050</td> <td>    0.025</td> <td>    0.199</td> <td> 0.842</td> <td>   -0.044</td> <td>    0.054</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.056</td> <th>  Durbin-Watson:     </th> <td>   1.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.972</td> <th>  Jarque-Bera (JB):  </th> <td>   0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.001</td> <th>  Prob(JB):          </th> <td>   0.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.013</td> <th>  Cond. No.          </th> <td>    149.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.999\n",
       "Model:                            OLS   Adj. R-squared:                  0.999\n",
       "Method:                 Least Squares   F-statistic:                 1.505e+06\n",
       "Date:                Mon, 23 Aug 2021   Prob (F-statistic):               0.00\n",
       "Time:                        11:32:17   Log-Likelihood:                -11366.\n",
       "No. Observations:                4546   AIC:                         2.274e+04\n",
       "Df Residuals:                    4542   BIC:                         2.277e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           -0.1340      0.103     -1.303      0.193      -0.336       0.068\n",
       "TV               3.5626      0.003   1051.118      0.000       3.556       3.569\n",
       "Radio           -0.0040      0.010     -0.406      0.685      -0.023       0.015\n",
       "Social_Media     0.0050      0.025      0.199      0.842      -0.044       0.054\n",
       "==============================================================================\n",
       "Omnibus:                        0.056   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.972   Jarque-Bera (JB):                0.034\n",
       "Skew:                          -0.001   Prob(JB):                        0.983\n",
       "Kurtosis:                       3.013   Cond. No.                         149.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols2=OLS(y,xx).fit() # 상수항 포함\n",
    "ols2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065c6d68-f370-4d5b-b8da-ea4cb2fc76b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>7.521e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 23 Aug 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:41:28</td>     <th>  Log-Likelihood:    </th> <td> -11366.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4546</td>      <th>  AIC:               </th> <td>2.275e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4539</td>      <th>  BIC:               </th> <td>2.279e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>   -0.1033</td> <td>    0.130</td> <td>   -0.797</td> <td> 0.426</td> <td>   -0.358</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Influencer[T.Mega]</th>  <td>    0.0116</td> <td>    0.124</td> <td>    0.094</td> <td> 0.926</td> <td>   -0.232</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Influencer[T.Micro]</th> <td>   -0.0569</td> <td>    0.124</td> <td>   -0.458</td> <td> 0.647</td> <td>   -0.300</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Influencer[T.Nano]</th>  <td>   -0.0739</td> <td>    0.125</td> <td>   -0.593</td> <td> 0.553</td> <td>   -0.318</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>                  <td>    3.5626</td> <td>    0.003</td> <td> 1050.472</td> <td> 0.000</td> <td>    3.556</td> <td>    3.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>               <td>   -0.0039</td> <td>    0.010</td> <td>   -0.399</td> <td> 0.690</td> <td>   -0.023</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_Media</th>        <td>    0.0045</td> <td>    0.025</td> <td>    0.179</td> <td> 0.858</td> <td>   -0.044</td> <td>    0.053</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.067</td> <th>  Durbin-Watson:     </th> <td>   1.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.967</td> <th>  Jarque-Bera (JB):  </th> <td>   0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.001</td> <th>  Prob(JB):          </th> <td>   0.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.015</td> <th>  Cond. No.          </th> <td>    288.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.999\n",
       "Model:                            OLS   Adj. R-squared:                  0.999\n",
       "Method:                 Least Squares   F-statistic:                 7.521e+05\n",
       "Date:                Mon, 23 Aug 2021   Prob (F-statistic):               0.00\n",
       "Time:                        11:41:28   Log-Likelihood:                -11366.\n",
       "No. Observations:                4546   AIC:                         2.275e+04\n",
       "Df Residuals:                    4539   BIC:                         2.279e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================\n",
       "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Intercept              -0.1033      0.130     -0.797      0.426      -0.358       0.151\n",
       "Influencer[T.Mega]      0.0116      0.124      0.094      0.926      -0.232       0.255\n",
       "Influencer[T.Micro]    -0.0569      0.124     -0.458      0.647      -0.300       0.187\n",
       "Influencer[T.Nano]     -0.0739      0.125     -0.593      0.553      -0.318       0.170\n",
       "TV                      3.5626      0.003   1050.472      0.000       3.556       3.569\n",
       "Radio                  -0.0039      0.010     -0.399      0.690      -0.023       0.015\n",
       "Social_Media            0.0045      0.025      0.179      0.858      -0.044       0.053\n",
       "==============================================================================\n",
       "Omnibus:                        0.067   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.967   Jarque-Bera (JB):                0.043\n",
       "Skew:                          -0.001   Prob(JB):                        0.979\n",
       "Kurtosis:                       3.015   Cond. No.                         288.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_list=list(dat1.columns[:-1])\n",
    "'+'.join(var_list)\n",
    "form='Sales~'+'+'.join(var_list)\n",
    "ols3=ols('Sales~TV+Radio+Social_Media',data=dat1).fit()\n",
    "ols3.summary()\n",
    "\n",
    "ols4=ols(form,data=dat1).fit()\n",
    "ols4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad19ffc-98ad-4d63-92d6-e450e97f0861",
   "metadata": {},
   "source": [
    "# 2번 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c9ca852-d5c8-491c-955f-d26fc145172e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 02 유형(DataSet_02.csv 이용)\n",
    "# 구분자 : comma(“,”), 200 Rows, 6 Columns, UTF-8 인코딩\n",
    "\n",
    "# 환자의 상태와 그에 따라 처방된 약에 대한 정보를 분석하고자한다\n",
    "# \n",
    "# 컬 럼 / 정 의  / Type\n",
    "# Age  / 연령 / Integer\n",
    "# Sex / 성별 / String\n",
    "# BP / 혈압 레벨 / String\n",
    "# Cholesterol / 콜레스테롤 레벨 /  String\n",
    "# Na_to_k / 혈액 내 칼륨에 대비한 나트륨 비율 / Double\n",
    "# Drug / Drug Type / String\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "dataset2=pd.read_csv('Dataset_02.csv')\n",
    "dataset2.columns\n",
    "dataset2.dtypes\n",
    "dataset2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6082de2-fb4a-45d8-a54d-a44ef9a29217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 1.해당 데이터에 대한 EDA를 수행하고, 여성으로 혈압이 High, Cholesterol이 Normal인\n",
    "# 환자의 전체에 대비한 비율이 얼마인지 소수점 네 번째 자리에서 반올림하여 소수점 셋째\n",
    "# 자리까지 기술하시오. (답안 예시) 0.123\n",
    "# =============================================================================\n",
    "import numpy as np \n",
    "Q1=pd.crosstab(index=dataset2.Sex,columns=dataset2.Cholesterol,normalize=True)\n",
    "\n",
    "# Q1=pd.pivot_table(index=['Sex','BP'],\n",
    "#                   columns=['Cholesterol'],\n",
    "#                   values=['Drug'],\n",
    "#                   aggfunc={'Age':np.mean,'Drug':np.count})\n",
    "#                   #normalize=True)\n",
    "# 예전 버전으로 지금 진행하면 오류가 생긴다.\n",
    "    \n",
    "Q1=pd.pivot_table(index=['Sex','BP'],\n",
    "                  columns=['Cholesterol'],\n",
    "                  values=['Drug'],\n",
    "                  data=dataset2,\n",
    "                  aggfunc='count')/len(dataset2)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dc75c58-ae96-481f-854b-70054559a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Age, Sex, BP, Cholesterol 및 Na_to_k 값이 Drug 타입에 영향을 미치는지 확인하기\n",
    "# 위하여 아래와 같이 데이터를 변환하고 분석을 수행하시오. \n",
    "# - Age_gr 컬럼을 만들고, Age가 20 미만은 ‘10’, 20부터 30 미만은 ‘20’, 30부터 40 미만은\n",
    "# ‘30’, 40부터 50 미만은 ‘40’, 50부터 60 미만은 ‘50’, 60이상은 ‘60’으로 변환하시오. \n",
    "# - Na_K_gr 컬럼을 만들고 Na_to_k 값이 10이하는 ‘Lv1’, 20이하는 ‘Lv2’, 30이하는 ‘Lv3’, 30 \n",
    "# 초과는 ‘Lv4’로 변환하시오.\n",
    "# - Sex, BP, Cholesterol, Age_gr, Na_K_gr이 Drug 변수와 영향이 있는지 독립성 검정을\n",
    "# 수행하시오.\n",
    "# - 검정 수행 결과, Drug 타입과 연관성이 있는 변수는 몇 개인가? 연관성이 있는 변수\n",
    "# 가운데 가장 큰 p-value를 찾아 소수점 여섯 번째 자리 이하는 버리고 소수점 다섯\n",
    "# 번째 자리까지 기술하시오.\n",
    "# (답안 예시) 3, 1.23456\n",
    "# =============================================================================\n",
    "\n",
    "# Tip. 변수 생성 후 카이스퀘어 검정\n",
    "\n",
    "# 변수 변환\n",
    "import numpy as np\n",
    "# np.where\n",
    "# Series.cut()\n",
    "\n",
    "Q2=dataset2.copy()\n",
    "\n",
    "Q2['Age_gr']=np.where(Q2.Age<20,'10',\n",
    "                     np.where(Q2.Age<30,'20',\n",
    "                            np.where(Q2.Age<40,'30',\n",
    "                                    np.where(Q2.Age<50,'40',\n",
    "                                             np.where(Q2.Age<60,'50','60',)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f71c5c88-7e37-4ab0-a034-29a7a3274339",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_gr=pd.cut(Q2.Age,[0,20,30,40,50,60,Q2.Age.max()+1],right=False,\n",
    "      labels=['10','20','30','40','50','60'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f941c99-5407-4b74-a417-42a4da3610dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-db537458ae83>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-db537458ae83>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    np.where(Q2['Na_to_K]<=20,'Lv2',\u001b[0m\n\u001b[1;37m                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Q2['Na_k_gr']=np.where(Q2['Na_to_K']<=10,'Lv1',\n",
    "                      np.where(Q2['Na_to_K]<=20,'Lv2',\n",
    "                              np.where(Q2['Na_to_K']<=30,'Lv3','Lv4')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1e7f1a0-8e15-47e4-94c7-4afa1c59ef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007010113024729462\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as sc\n",
    "\n",
    "# 입력 값이 빈도 테이블로 들어가도록 변경\n",
    "\n",
    "['Age','Sex','BP','Cholesterol','Age_gr','Na_k_gr','Drug']\n",
    "\n",
    "Age_t=pd.crosstab(Q2.Age_gr,Q2.Drug)\n",
    "out_Age_t=sc.chi2_contingency(Age_t)\n",
    "print(out_Age_t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e8a1136-e142-4418-8a65-05610e86090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age_gr 0.0007010113024729462\n",
      "Sex 0.7138369773987128\n",
      "BP 5.0417334144665895e-27\n",
      "Cholesterol 0.0005962588389856497\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Na_k_gr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Na_k_gr'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-2c4d07526880>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mQ2_temp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Age_gr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'BP'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Cholesterol'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Na_k_gr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtemp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQ2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDrug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mout_Age_t\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchi2_contingency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_Age_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\multi\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Na_k_gr'"
     ]
    }
   ],
   "source": [
    "Q2_temp=[]\n",
    "for i in ['Age_gr','Sex','BP','Cholesterol','Na_k_gr'] :\n",
    "    temp=pd.crosstab(Q2[i],Q2.Drug)\n",
    "    out_Age_t=sc.chi2_contingency(temp)\n",
    "    print(i,out_Age_t[1])\n",
    "    Q2_temp=Q2_temp+[[i,out_Age_t[1]]]\n",
    "\n",
    "Q2_temp=pd.DataFrame(Q2_temp)\n",
    "Q2_temp2=Q2_temp[Q2_temp.pvalues<0.05]\n",
    "len(Q2_temp2)\n",
    "\n",
    "Q2_temp2.sort_values(by='pvalues').tail(1)\n",
    "Q2_temp.sort_values(by=1)[1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f90b3-afc7-4555-ba1d-370bc7391185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 3.Sex, BP, Cholesterol 등 세 개의 변수를 다음과 같이 변환하고 의사결정나무를 이용한\n",
    "# 분석을 수행하시오.\n",
    "# - Sex는 M을 0, F를 1로 변환하여 Sex_cd 변수 생성\n",
    "# - BP는 LOW는 0, NORMAL은 1 그리고 HIGH는 2로 변환하여 BP_cd 변수 생성\n",
    "# - Cholesterol은 NORMAL은 0, HIGH는 1로 변환하여 Ch_cd 생성\n",
    "# - Age, Na_to_k, Sex_cd, BP_cd, Ch_cd를 Feature로, Drug을 Label로 하여 의사결정나무를\n",
    "# 수행하고 Root Node의 split feature와 split value를 기술하시오. \n",
    "# 이 때 split value는 소수점 셋째 자리까지 반올림하여 기술하시오. (답안 예시) Age, \n",
    "# 12.345\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree,export_text\n",
    "\n",
    "Q3=datasets.copy()\n",
    "\n",
    "Q3.BP.value_counts()\n",
    "Q3['Sex_cd']=np.where(Q3.Sex=='M',0,1)\n",
    "Q3['BP_cd']=np.where(Q3.BP=='LOW',0,np.where(Q3.BP=='NORMAL',1,2))\n",
    "\n",
    "Q3['Ch_cd']=np.where(Q3.Cholesterol=='NORMAL',0,1)\n",
    "\n",
    "x_var=['Age','Na_to_K','Sex_cd','BP_cd','CH-cd']\n",
    "\n",
    "dt=DecisionTreeClassifier().fit(Q3[x_var],Q3.Drug)\n",
    "\n",
    "plot_tree(dt,feature_names=x_var,class_names=Q3.Drug.unique())\n",
    "export_text(dt,feature_names=x_var,decimals=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e09f6f-27a4-4f7c-8497-e56c7b518e95",
   "metadata": {},
   "source": [
    "# 3번 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8ff5a-2c17-4dbf-867d-e75fa2cd95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 03 유형(DataSet_03.csv 이용)\n",
    "# \n",
    "# 구분자 : comma(“,”), 5,001 Rows, 8 Columns, UTF-8 인코딩\n",
    "# 안경 체인을 운영하고 있는 한 회사에서 고객 사진을 바탕으로 안경의 사이즈를\n",
    "# 맞춤 제작하는 비즈니스를 기획하고 있다. 우선 데이터만으로 고객의 성별을\n",
    "# 파악하는 것이 가능할 지를 연구하고자 한다.\n",
    "#\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# long_hair / 머리카락 길이 (0 – 길지 않은 경우 / 1 – 긴\n",
    "# 경우) / Integer\n",
    "# forehead_width_cm / 이마의 폭 (cm) / Double\n",
    "# forehead_height_cm / 이마의 높이 (cm) / Double\n",
    "# nose_wide / 코의 넓이 (0 – 넓지 않은 경우 / 1 – 넓은 경우) / Integer\n",
    "# nose_long / 코의 길이 (0 – 길지 않은 경우 / 1 – 긴 경우) / Integer\n",
    "# lips_thin / 입술이 얇은지 여부 0 – 얇지 않은 경우 / 1 –\n",
    "# 얇은 경우) / Integer\n",
    "# distance_nose_to_lip_long / 인중의 길이(0 – 인중이 짧은 경우 / 1 – 인중이\n",
    "# 긴 경우) / Integer\n",
    "# gender / 성별 (Female / Male) / String\n",
    "# =============================================================================\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0dd11b-ba95-4e14-a7db-f72104d68a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 1.이마의 폭(forehead_width_cm)과 높이(forehead_height_cm) 사이의\n",
    "# 비율(forehead_ratio)에 대해서 평균으로부터 3 표준편차 밖의 경우를 이상치로\n",
    "# 정의할 때, 이상치에 해당하는 데이터는 몇 개인가? (답안 예시) 10\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a30c3b-1c9c-4e37-9224-a142c1f62e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 2.성별에 따라 forehead_ratio 평균에 차이가 있는지 적절한 통계 검정을 수행하시오.\n",
    "# - 검정은 이분산을 가정하고 수행한다.\n",
    "# - 검정통계량의 추정치는 절대값을 취한 후 소수점 셋째 자리까지 반올림하여\n",
    "# 기술하시오.\n",
    "# - 신뢰수준 99%에서 양측 검정을 수행하고 결과는 귀무가설 기각의 경우 Y로, 그렇지\n",
    "# 않을 경우 N으로 답하시오. (답안 예시) 1.234, Y\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d9dff-7851-4df6-8666-f558641b40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 3.주어진 데이터를 사용하여 성별을 구분할 수 있는지 로지스틱 회귀분석을 적용하여\n",
    "# 알아 보고자 한다. \n",
    "# - 데이터를 7대 3으로 나누어 각각 Train과 Test set로 사용한다. 이 때 seed는 123으로\n",
    "# 한다.\n",
    "# - 원 데이터에 있는 7개의 변수만 Feature로 사용하고 gender를 label로 사용한다.\n",
    "# (forehead_ratio는 사용하지 않음)\n",
    "# - 로지스틱 회귀분석 예측 함수와 Test dataset를 사용하여 예측을 수행하고 정확도를\n",
    "# 평가한다. 이 때 임계값은 0.5를 사용한다. \n",
    "# - Male의 Precision 값을 소수점 둘째 자리까지 반올림하여 기술하시오. (답안 예시) \n",
    "# 0.12\n",
    "# \n",
    "# \n",
    "# (참고) \n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import metrics\n",
    "# train_test_split 의 random_state = 123\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3111a16-f5aa-4558-bf8a-d4093394209b",
   "metadata": {},
   "source": [
    "# 4번 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cbc177-4d75-4fba-ab0a-504c41efd4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 04 유형(DataSet_04.csv 이용)\n",
    "#\n",
    "#구분자 : comma(“,”), 6,718 Rows, 4 Columns, UTF-8 인코딩\n",
    "\n",
    "# 한국인의 식생활 변화가 건강에 미치는 영향을 분석하기에 앞서 육류\n",
    "# 소비량에 대한 분석을 하려고 한다. 확보한 데이터는 세계 각국의 1인당\n",
    "# 육류 소비량 데이터로 아래와 같은 내용을 담고 있다.\n",
    "\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# LOCATION / 국가명 / String\n",
    "# SUBJECT / 육류 종류 (BEEF / PIG / POULTRY / SHEEP) / String\n",
    "# TIME / 연도 (1990 ~ 2026) / Integer\n",
    "# Value / 1인당 육류 소비량 (KG) / Double\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "# (참고)\n",
    "# #1\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# #2\n",
    "# from scipy.stats import ttest_rel\n",
    "# #3\n",
    "# from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d7046-af32-4539-b03b-ba512ab6ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 1.한국인의 1인당 육류 소비량이 해가 갈수록 증가하는 것으로 보여 상관분석을 통하여\n",
    "# 확인하려고 한다. \n",
    "# - 데이터 파일로부터 한국 데이터만 추출한다. 한국은 KOR로 표기되어 있다.\n",
    "# - 년도별 육류 소비량 합계를 구하여 TIME과 Value간의 상관분석을 수행하고\n",
    "# 상관계수를 소수점 셋째 자리에서 반올림하여 소수점 둘째 자리까지만 기술하시오. \n",
    "# (답안 예시) 0.55\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3516e5-a2b7-406e-a62f-73dd8c9be60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 2. 한국 인근 국가 가운데 식생의 유사성이 상대적으로 높은 일본(JPN)과 비교하여, 연도별\n",
    "# 소비량에 평균 차이가 있는지 분석하고자 한다.\n",
    "# - 두 국가의 육류별 소비량을 연도기준으로 비교하는 대응표본 t 검정을 수행하시오.\n",
    "# - 두 국가 간의 연도별 소비량 차이가 없는 것으로 판단할 수 있는 육류 종류를 모두\n",
    "# 적으시오. (알파벳 순서) (답안 예시) BEEF, PIG, POULTRY, SHEEP\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db6414-e463-4ca3-b389-c35f5ba1e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 3.(한국만 포함한 데이터에서) Time을 독립변수로, Value를 종속변수로 하여 육류\n",
    "# 종류(SUBJECT) 별로 회귀분석을 수행하였을 때, 가장 높은 결정계수를 가진 모델의\n",
    "# 학습오차 중 MAPE를 반올림하여 소수점 둘째 자리까지 기술하시오. (답안 예시) 21.12\n",
    "# (MAPE : Mean Absolute Percentage Error, 평균 절대 백분율 오차)\n",
    "# (MAPE = Σ ( | y - y ̂ | / y ) * 100/n ))\n",
    "# \n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a4263-c4c5-4c33-839f-81cdec203c85",
   "metadata": {},
   "source": [
    "# 5번 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef8aa6-f0f1-4588-aebf-defef1731790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 05 유형(DataSet_05.csv 이용)\n",
    "#\n",
    "# 구분자 : comma(“,”), 8,068 Rows, 12 Columns, UTF-8 인코딩\n",
    "#\n",
    "# A자동차 회사는 신규 진입하는 시장에 기존 모델을 판매하기 위한 마케팅 전략을 \n",
    "# 세우려고 한다. 기존 시장과 고객 특성이 유사하다는 전제 하에 기존 고객을 세분화하여\n",
    "# 각 그룹의 특징을 파악하고, 이를 이용하여 신규 진입 시장의 마케팅 계획을 \n",
    "# 수립하고자 한다. 다음은 기존 시장 고객에 대한 데이터이다.\n",
    "#\n",
    "\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# ID / 고유 식별자 / Double\n",
    "# Age / 나이 / Double\n",
    "# Age_gr / 나이 그룹 (10/20/30/40/50/60/70) / Double\n",
    "# Gender / 성별 (여성 : 0 / 남성 : 1) / Double\n",
    "# Work_Experience / 취업 연수 (0 ~ 14) / Double\n",
    "# Family_Size / 가족 규모 (1 ~ 9) / Double\n",
    "# Ever_Married / 결혼 여부 (Unknown : 0 / No : 1 / Yes : 2) / Double\n",
    "# Graduated / 재학 중인지 여부 / Double\n",
    "# Profession / 직업 (Unknown : 0 / Artist ~ Marketing 등 9개) / Double\n",
    "# Spending_Score / 소비 점수 (Average : 0 / High : 1 / Low : 2) / Double\n",
    "# Var_1 / 내용이 알려지지 않은 고객 분류 코드 (0 ~ 7) / Double\n",
    "# Segmentation / 고객 세분화 결과 (A ~ D) / String\n",
    "# =============================================================================\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967bf07-9b1a-4e02-86d7-6d25881e6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(참고)\n",
    "#1\n",
    "# import pandas as pd\n",
    "# #2\n",
    "# from scipy.stats import chi2_contingency\n",
    "# #3\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import metrics\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.tree import export_graphviz\n",
    "# import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53dda4-e1c7-481e-a664-dd22d7b7030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 1.위의 표에 표시된 데이터 타입에 맞도록 전처리를 수행하였을 때, 데이터 파일 내에\n",
    "# 존재하는 결측값은 모두 몇 개인가? 숫자형 데이터와 문자열 데이터의 결측값을\n",
    "# 모두 더하여 답하시오.\n",
    "# (String 타입 변수의 경우 White Space(Blank)를 결측으로 처리한다) (답안 예시) 123\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de83ad8-4e4a-4aa1-98f2-4016b038f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 2.이어지는 분석을 위해 결측값을 모두 삭제한다. 그리고, 성별이 세분화(Segmentation)에\n",
    "# 영향을 미치는지 독립성 검정을 수행한다. 수행 결과, p-value를 반올림하여 소수점\n",
    "# 넷째 자리까지 쓰고, 귀무가설을 기각하면 Y로, 기각할 수 없으면 N으로 기술하시오. \n",
    "# (답안 예시) 0.2345, N\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1bc310-47d4-4e2b-b167-bc068fa487a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# =============================================================================\n",
    "# 3.Segmentation 값이 A 또는 D인 데이터만 사용하여 의사결정 나무 기법으로 분류\n",
    "# 정확도를\n",
    "# 측정해 본다. \n",
    "# - 결측치가 포함된 행은 제거한 후 진행하시오.\n",
    "# - Train대 Test 7대3으로 데이터를 분리한다. (Seed = 123)\n",
    "# - Train 데이터를 사용하여 의사결정나무 학습을 수행하고, Test 데이터로 평가를\n",
    "# 수행한다.\n",
    "# - 의사결정나무 학습 시, 다음과 같이 설정하시오:\n",
    "# • Feature: Age_gr, Gender, Work_Experience, Family_Size, \n",
    "#             Ever_Married, Graduated, Spending_Score\n",
    "# • Label : Segmentation\n",
    "# • Parameter : Gini / Max Depth = 7 / Seed = 123\n",
    "# 이 때 전체 정확도(Accuracy)를 소수점 셋째 자리 이하는 버리고 소수점 둘째자리까지\n",
    "# 기술하시오.\n",
    "# (답안 예시) 0.12\n",
    "# ============================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
